{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bd959a-2273-48b5-93a3-34329905abe0",
   "metadata": {},
   "source": [
    "# TaXGBoost_Example.ipynb\n",
    "\n",
    "This notebook is an edited version (forked, see below) of a notebooks that uses Rapids and XGBoost for model training and prediction using the NYC taxi database. The basic flow of the experiment is from [this Dell whitepaper on Rapids performance on different configurations of Dell Servers](https://1drv.ms/b/s!Am_o6IxX4xnWv1s-0m-Rra-K0Ywt) (provided by Bhavesh Patel of Dell).\n",
    "\n",
    "Ultimately, the purpose of the edits are to create a version of this notebook for use within the OneAPI development (specifically on the Intel DevCloud) including:\n",
    "\n",
    "- Comparing XGBoost Performance on Intel and Nvidia Configurations\n",
    "    - Intel Platforms [Devcloud hardware found by console command in ~Sept of 2021, accessible here](https://1drv.ms/x/s!Am_o6IxX4xnWwVpPvh-VGGXQim8Y?e=peFxsn)\n",
    "        - Devcloud (by proccessor type, most are 1 or 2 GPU/Node)\n",
    "            - CPU\n",
    "                - i9-10920x\n",
    "                - e-2176g\n",
    "                - clx\n",
    "                - gold6128\n",
    "            - GPU\n",
    "                - \"gen 9\" (Presumably an iGPU)\n",
    "                - Iris Xe max (Presumably an dGPU, though Bhavesh has mentioned that this is a lower/mobile version)\n",
    "        - Dell Server\n",
    "            - Bhaves should get access to a Intel GPU server with a better GPU this December (2021)\n",
    "                - This is especially advantageous, since Devcloud dGPU nodes are very memory limited (32 gb)\n",
    "    - Nvidia Platforms (by node type)\n",
    "        - HiPerGator [Info here](https://www.rc.ufl.edu/services/hipergator/)\n",
    "            - AI NVidia DGX A100 SuperPod\n",
    "                - 140 NVIDIA DGX A100 Nodes\n",
    "                    - 2x AMD EPYC 7742 (Rome) 64-Core processors with Simultaneous Multi-Threading (SMT) enabled presenting 256 cores per node\n",
    "                    - 2TB RAM\n",
    "                    - 8x NVIDIA A100 80GB Tensor Core GPUs\n",
    "                    - NVSWITCH technology that supports integration of all 8 A100 GPUâ€™s in a system with unified memory space\n",
    "                    - 10x HDR IB non-blocking interfaces for inter-node communication\n",
    "                    - 2x 100GbE ethernet interfaces\n",
    "                    - 28TB NVMe local storage\n",
    "            - HiperGator 3.0 (Jan 2021)\n",
    "                - Intel Xeon E5-2698 v3 Haswell, 4GB/core (could possibly use Intel4py versions as a comparison)\n",
    "            - HiPerGator 3.0 (Same pase, but Q2 2021)\n",
    "                - AMD EPYX 7702 Rome, 8 GB/core\n",
    "            - HiperGator 2.0 (2015)\n",
    "                - AMD EPYC 75F3 Milan, 8GB/core\n",
    "        - Dell Servers (Used for the whitepaper, and Bhavesh is currently in the process of getting us access to these nodes or similar as well)\n",
    "            -\n",
    "            -\n",
    "            -\n",
    "            -\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d84268-5eee-4b6a-911b-a4e79f943b31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sources where the code came from:\n",
    "-  [First version of this file came from this file/repo (NYCTaxi-E2E.ipynb/rapids notebooks-contrib)](https://github.com/rapidsai-community/notebooks-contrib/blob/main/community_tutorials_and_guides/taxi/NYCTaxi-E2E.ipynb)\n",
    "-  [This link contains a similar (maybe forked) version of this notebook that I used for reference](https://jovian.ai/allenkong221/nyc-taxi-fare/v/1?utm_source=embed#C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fda33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "#import lightgbm as lgbm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f125d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/inteloneapi/intelpython/latest/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3173: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "'''if you get 'ModuleNotFoundError: No module named 'gcsfs', run `!pip install gcsfs` \n",
    "'''\n",
    "#base_path = 'gcs://anaconda-public-data/nyc-taxi/csv/'\n",
    "\n",
    "#df_2014 = dask_cudf.read_csv(base_path+'2014/yellow_*.csv')\n",
    "\n",
    "\n",
    "#Ok, we need to load in data here, but not the old way\n",
    "data_path = '/home/u117430/rapids/data/'\n",
    "#df_2014 = pd.read_csv(data_path+'2014/yellow_*.csv')\n",
    "df_2014 = pd.read_csv(data_path+'yellow_tripdata_2014-11.csv')\n",
    "#df_2015 = pd.read_csv(data_path+'yellow_tripdata_2015-11.csv')\n",
    "df_2016 = pd.read_csv(data_path+'yellow_tripdata_2016-11.csv')\n",
    "    #Sources:\n",
    "        #https://github.com/oneapi-src/oneAPI-samples/blob/master/AI-and-Analytics/End-to-end-Workloads/Census/census_modin.ipynb\n",
    "        #:https://examples.dask.org/dataframes/01-data-access.html#Read-CSV-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca26ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of required columns and their datatypes\n",
    "must_haves = {\n",
    "     ' pickup_datetime': 'datetime64[s]',\n",
    "     ' dropoff_datetime': 'datetime64[s]',\n",
    "     ' passenger_count': 'int32',\n",
    "     ' trip_distance': 'float32',\n",
    "     ' pickup_longitude': 'float32',\n",
    "     ' pickup_latitude': 'float32',\n",
    "     ' rate_code': 'int32',\n",
    "     ' dropoff_longitude': 'float32',\n",
    "     ' dropoff_latitude': 'float32',\n",
    "     ' fare_amount': 'float32'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4674a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(ddf, must_haves):\n",
    "    tmp = {col:col.strip().lower() for col in list(ddf.columns)}     # replace the extraneous spaces in column names and lower the font type\n",
    "        #In this case, what is tmp? It looks like tmp is jit dictionary built to hold the column names that have been fed in, but stripped of spaces and lower cased\n",
    "    ddf = ddf.rename(columns=tmp) #Then, this dictionary is used to rename the columns\n",
    "        \n",
    "        #Rename documentionation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html\n",
    "\n",
    "    ddf = ddf.rename(columns={\n",
    "        'tpep_pickup_datetime': 'pickup_datetime',\n",
    "        'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "        'ratecodeid': 'rate_code'\n",
    "    })  #More name changing. Just changing column names to an easier to read format\n",
    "    \n",
    "    ddf['pickup_datetime'] = ddf['pickup_datetime'].astype('datetime64[ms]')       #Looks to just recast datatype to a date/time format\n",
    "    ddf['dropoff_datetime'] = ddf['dropoff_datetime'].astype('datetime64[ms]')\n",
    "\n",
    "        #Astype doc: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html\n",
    "    \n",
    "    #Here's where things get tricky. Let's look at df.map_partitions() vs df.apply()\n",
    "    \n",
    "        #DataFrame.map_partitions(func, *args, **kwargs)\n",
    "            #Desc: Apply Python function on each DataFrame partition.\n",
    "            #Doc: https://docs.dask.org/en/latest/generated/dask.dataframe.DataFrame.map_partitions.html#dask.dataframe.DataFrame.map_partitions\n",
    "        \n",
    "        #DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)\n",
    "            #Desc: Apply a function along an axis of the DataFrame.\n",
    "\n",
    "        #So apply may not be what we want. map_partitions works on partitions, while apply works on axis\n",
    "            #FYI: apply apparently shouldn't be used b/c it's horribly inefficient\n",
    "            #DASK dataframes are made up of partitions, which are pandas dataframes?\n",
    "                #https://docs.dask.org/en/latest/dataframe-best-practices.html\n",
    "                #https://docs.dask.org/en/latest/dataframe-design.html#dataframe-design-partitions\n",
    "\n",
    "    \n",
    "    for col in ddf.columns:                                   #For each column\n",
    "        if col not in must_haves:                             #If the column isn't in the dictionary\n",
    "            ddf = ddf.drop(columns=col)                       #Remove it\n",
    "            continue\n",
    "        # if column was read as a string, recast as float\n",
    "        if ddf[col].dtype == 'object':                        #If the column was a string\n",
    "            ddf[col] = ddf[col].str.fillna('-1')              #Turn it into a float with these two lines\n",
    "            ddf[col] = ddf[col].astype('float32')\n",
    "        else:\n",
    "            # downcast from 64bit to 32bit types\n",
    "            # Tesla T4 are faster on 32bit ops\n",
    "            if 'int' in str(ddf[col].dtype):                 #Convert int's to 32 bit ints\n",
    "                ddf[col] = ddf[col].astype('int32')\n",
    "            if 'float' in str(ddf[col].dtype):               #Convert doubles to floats\n",
    "                ddf[col] = ddf[col].astype('float32')\n",
    "            ddf[col] = ddf[col].fillna(-1)\n",
    "    \n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1258f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2014 = df_2014.map_partitions(clean, must_haves, meta=must_haves)\n",
    "taxi_df = df_2014\n",
    "tmp = {col:col.strip().lower() for col in list(taxi_df.columns)}\n",
    "taxi_df = taxi_df.rename(columns=tmp) #Then, this dictionary is used to rename the columns\n",
    "\n",
    "taxi_df = taxi_df.rename(columns={\n",
    "        'tpep_pickup_datetime': 'pickup_datetime',\n",
    "        'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "        'ratecodeid': 'rate_code'\n",
    "    }) \n",
    "\n",
    "taxi_df['pickup_datetime'] = taxi_df['pickup_datetime'].astype('datetime64[ms]')       #Looks to just recast datatype to a date/time format\n",
    "taxi_df['dropoff_datetime'] = taxi_df['dropoff_datetime'].astype('datetime64[ms]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56691056-4dc7-49c2-aea6-2a88c010822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-11-01 00:47:00</td>\n",
       "      <td>2014-11-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-73.960960</td>\n",
       "      <td>40.818780</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.923620</td>\n",
       "      <td>40.808400</td>\n",
       "      <td>CRD</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-11-01 00:28:00</td>\n",
       "      <td>2014-11-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>-73.990148</td>\n",
       "      <td>40.729315</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.954933</td>\n",
       "      <td>40.769335</td>\n",
       "      <td>CRD</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-11-01 00:39:00</td>\n",
       "      <td>2014-11-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.52</td>\n",
       "      <td>-73.980122</td>\n",
       "      <td>40.742847</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.977007</td>\n",
       "      <td>40.784257</td>\n",
       "      <td>CRD</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-11-01 00:46:00</td>\n",
       "      <td>2014-11-01 00:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-73.932773</td>\n",
       "      <td>40.703382</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.951693</td>\n",
       "      <td>40.691347</td>\n",
       "      <td>CRD</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2014-11-01 00:06:00</td>\n",
       "      <td>2014-11-01 00:59:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8.18</td>\n",
       "      <td>-73.997955</td>\n",
       "      <td>40.729407</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.884077</td>\n",
       "      <td>40.748452</td>\n",
       "      <td>CSH</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0       VTS 2014-11-01 00:47:00 2014-11-01 01:00:00                5   \n",
       "1       VTS 2014-11-01 00:28:00 2014-11-01 01:00:00                5   \n",
       "2       VTS 2014-11-01 00:39:00 2014-11-01 01:00:00                2   \n",
       "3       VTS 2014-11-01 00:46:00 2014-11-01 00:56:00                1   \n",
       "4       VTS 2014-11-01 00:06:00 2014-11-01 00:59:00                3   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  rate_code  \\\n",
       "0           2.71        -73.960960        40.818780          1   \n",
       "1           4.67        -73.990148        40.729315          1   \n",
       "2           4.52        -73.980122        40.742847          1   \n",
       "3           1.70        -73.932773        40.703382          1   \n",
       "4           8.18        -73.997955        40.729407          1   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude payment_type  \\\n",
       "0                NaN         -73.923620         40.808400          CRD   \n",
       "1                NaN         -73.954933         40.769335          CRD   \n",
       "2                NaN         -73.977007         40.784257          CRD   \n",
       "3                NaN         -73.951693         40.691347          CRD   \n",
       "4                NaN         -73.884077         40.748452          CSH   \n",
       "\n",
       "   fare_amount  surcharge  mta_tax  tip_amount  tolls_amount  total_amount  \n",
       "0         11.5        0.5      0.5        2.40           0.0         14.90  \n",
       "1         23.5        0.5      0.5        6.00           0.0         30.50  \n",
       "2         17.0        0.5      0.5        4.38           0.0         22.38  \n",
       "3          8.5        0.5      0.5        2.25           0.0         11.75  \n",
       "4         37.5        0.5      0.5        0.00           0.0         38.50  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cb8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_df = dask.dataframe.multi.concat([df_2014, df_2015, df_2016])\n",
    "#taxi_df = pd.concat([df_2014, df_2016])\n",
    "#taxi_df = df_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e00440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi_df = taxi_df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372a7f58-2e25-46f8-9347-2d3d8b3139d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_taxi_df = taxi_df.drop(['vendor_id', 'store_and_fwd_flag', 'payment_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0596fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we calculated the h_distance let's drop the trip_distance column, and then do model training with XGB.\n",
    "#taxi_df = taxi_df.drop('trip_distance', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8632af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-01 00:47:00</td>\n",
       "      <td>2014-11-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-73.960960</td>\n",
       "      <td>40.818780</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.923620</td>\n",
       "      <td>40.808400</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-01 00:28:00</td>\n",
       "      <td>2014-11-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>-73.990148</td>\n",
       "      <td>40.729315</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.954933</td>\n",
       "      <td>40.769335</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-01 00:39:00</td>\n",
       "      <td>2014-11-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.52</td>\n",
       "      <td>-73.980122</td>\n",
       "      <td>40.742847</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.977007</td>\n",
       "      <td>40.784257</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-11-01 00:46:00</td>\n",
       "      <td>2014-11-01 00:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-73.932773</td>\n",
       "      <td>40.703382</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.951693</td>\n",
       "      <td>40.691347</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-01 00:06:00</td>\n",
       "      <td>2014-11-01 00:59:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8.18</td>\n",
       "      <td>-73.997955</td>\n",
       "      <td>40.729407</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.884077</td>\n",
       "      <td>40.748452</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0 2014-11-01 00:47:00 2014-11-01 01:00:00                5           2.71   \n",
       "1 2014-11-01 00:28:00 2014-11-01 01:00:00                5           4.67   \n",
       "2 2014-11-01 00:39:00 2014-11-01 01:00:00                2           4.52   \n",
       "3 2014-11-01 00:46:00 2014-11-01 00:56:00                1           1.70   \n",
       "4 2014-11-01 00:06:00 2014-11-01 00:59:00                3           8.18   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  rate_code  dropoff_longitude  \\\n",
       "0        -73.960960        40.818780          1         -73.923620   \n",
       "1        -73.990148        40.729315          1         -73.954933   \n",
       "2        -73.980122        40.742847          1         -73.977007   \n",
       "3        -73.932773        40.703382          1         -73.951693   \n",
       "4        -73.997955        40.729407          1         -73.884077   \n",
       "\n",
       "   dropoff_latitude  fare_amount  surcharge  mta_tax  tip_amount  \\\n",
       "0         40.808400         11.5        0.5      0.5        2.40   \n",
       "1         40.769335         23.5        0.5      0.5        6.00   \n",
       "2         40.784257         17.0        0.5      0.5        4.38   \n",
       "3         40.691347          8.5        0.5      0.5        2.25   \n",
       "4         40.748452         37.5        0.5      0.5        0.00   \n",
       "\n",
       "   tolls_amount  total_amount  \n",
       "0           0.0         14.90  \n",
       "1           0.0         30.50  \n",
       "2           0.0         22.38  \n",
       "3           0.0         11.75  \n",
       "4           0.0         38.50  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c831185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add features\n",
    "\n",
    "taxi_df['hour'] = taxi_df['pickup_datetime'].dt.hour\n",
    "taxi_df['year'] = taxi_df['pickup_datetime'].dt.year\n",
    "taxi_df['month'] = taxi_df['pickup_datetime'].dt.month\n",
    "taxi_df['day'] = taxi_df['pickup_datetime'].dt.day\n",
    "taxi_df['day_of_week'] = taxi_df['pickup_datetime'].dt.weekday\n",
    "taxi_df['is_weekend'] = (taxi_df['day_of_week']>=5).astype('int32')\n",
    "\n",
    "#calculate the time difference between dropoff and pickup.\n",
    "taxi_df['diff'] = taxi_df['dropoff_datetime'].astype('int64') - taxi_df['pickup_datetime'].astype('int64')\n",
    "taxi_df['diff']=(taxi_df['diff']/1000).astype('int64')\n",
    "\n",
    "taxi_df['pickup_latitude_r'] = taxi_df['pickup_latitude']//.01*.01\n",
    "taxi_df['pickup_longitude_r'] = taxi_df['pickup_longitude']//.01*.01\n",
    "taxi_df['dropoff_latitude_r'] = taxi_df['dropoff_latitude']//.01*.01\n",
    "taxi_df['dropoff_longitude_r'] = taxi_df['dropoff_longitude']//.01*.01\n",
    "\n",
    "#taxi_df = taxi_df.drop('pickup_datetime', axis=1)\n",
    "#taxi_df = taxi_df.drop('dropoff_datetime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2722a75-9568-44d5-bfc6-deea9d5d70d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendor_id\n",
      "pickup_datetime\n",
      "dropoff_datetime\n",
      "passenger_count\n",
      "trip_distance\n",
      "pickup_longitude\n",
      "pickup_latitude\n",
      "rate_code\n",
      "store_and_fwd_flag\n",
      "dropoff_longitude\n",
      "dropoff_latitude\n",
      "payment_type\n",
      "fare_amount\n",
      "surcharge\n",
      "mta_tax\n",
      "tip_amount\n",
      "tolls_amount\n",
      "total_amount\n",
      "hour\n",
      "year\n",
      "month\n",
      "day\n",
      "day_of_week\n",
      "is_weekend\n",
      "diff\n",
      "pickup_latitude_r\n",
      "pickup_longitude_r\n",
      "dropoff_latitude_r\n",
      "dropoff_longitude_r\n"
     ]
    }
   ],
   "source": [
    "for col in taxi_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a61105-c0dd-4c62-822d-72c10d0b2b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_taxi_df = taxi_df.drop(['pickup_datetime','dropoff_datetime','vendor_id', 'store_and_fwd_flag', 'payment_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b8d1c8e-0e06-43cb-b8e4-b493a427ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = final_taxi_df.drop('fare_amount', axis = 1), final_taxi_df['fare_amount']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fd7666-5c1f-4e15-97df-6297ab7b8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1471e96-ea49-436c-84a6-3751b0c39396",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0719f720-dd67-4dc9-a456-fb3511ae6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(final_taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38dd7bae-a52b-47de-a722-762be67fa505",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d8f658-3ee9-4c00-9e2f-18dc0b416f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'min_child_weight': 1, \n",
    "    'learning_rate': 0.05, \n",
    "    'colsample_bytree': 0.7, \n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.7,\n",
    "    'n_estimators': 5000,\n",
    "    'n_jobs': -1, \n",
    "    'booster' : 'gbtree', \n",
    "    'silent': 1,\n",
    "    'eval_metric': 'rmse'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "898fcb6d-434d-4cad-88d4-8594b0707157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:44:10] WARNING: /localdisk/tools/tc/agent2/work/30ccf72606c6a49e/base/conda-bld/xgboost_1623788730212/work/src/learner.cc:574: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:15.40109\tvalid-rmse:15.38414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/tmp/ipykernel_3965488/675482622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/intel/inteloneapi/intelpython/latest/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/inteloneapi/intelpython/latest/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/inteloneapi/intelpython/latest/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = xgb.train(xgb_params, dtrain, 700, watchlist, early_stopping_rounds=100, maximize=False, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4154bc5-15eb-45cc-9540-c74c1016c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(dtrain)\n",
    "y_pred = model.predict(dvalid)\n",
    "print('Train r2 score: ', r2_score(y_train_pred, y_train))\n",
    "print('Test r2 score: ', r2_score(y_test, y_pred))\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_pred, y_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Train RMSE: {train_rmse:.4f}')\n",
    "print(f'Test RMSE: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9dd3b-7df1-4cd9-9b1f-ab4f8fc3887d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (IntelÂ® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
